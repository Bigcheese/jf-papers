===================================================================
D4523 ``constexpr std::thread::hardware_{true,false}_sharing_size``
===================================================================

:Author: JF Bastien
:Contact: jfb@google.com
:Author: Olivier Giroux
:Contact: ogiroux@nvidia.com
:Date: 2015-05-08
:URL: https://github.com/jfbastien/papers/blob/master/source/D4523.rst

.. TODO Update the URL above when this becomes an N paper.

---------
Rationale
---------

Each architecture implementation has a cacheline size which never
changes. Indeed, this number is deeply embedded in the caching hardware's
implementation, yet C++ doesn't expose this number as a ``constexpr``. This is
partly due to this cacheline size changing from one architecture implementation
to another within the same Instruction Set Architecture. Knowing which ISA the
compiler targets is therefore insufficient to get an exact cacheline size: one
has to target a specific architecture implementation.

The current methods to obtain the cacheline size are all runtime methods, not
``constexpr`` values, and are either ISA-dependent, OS-dependent, or use cache
timing. See the appendix_ for examples.

Having a ``constexpr`` value is useful, even when the ``constexpr`` is only a
likely good value instead of the exact one. This allows setting ``alignas`` on
datastructures. It isn't a guarantee, merely a good guess at what would
work. This is useful to separate members in a class which have different access
patterns based on the algorithm. A developer can reason about the caching
protocol, e.g. MOESI, and group members which the algorithms makes exclusive to
a thread of execution and separate them from elements which are shared between
threads of execution.

Typical examples where this matters are:

* Multiple-producer and multiple-consumer queue.
* The ``barrier`` example, as illustrated in N4522_.
* Grouping an atomic variable with the data it protects.
* Preventing false-sharing between objects with different runtime access
  patterns from different threads.
* Promoting true-sharing between objects which have the same runtime access
  patterns.

.. _N4522: http://wg21.link/N4522

The only significant cacheline size in these circumstances is L1 cacheline
size. Advanced high-performance applications will care about the effects of
cache associativity and ways, multiple cache hierarchy, page size, TLB size,
number of sockets, in-rack distance, intra-datacenter distance, inter-datacenter
distance, and much more. This paper explicity doesn't address second-order and
N\ :sup:`th`-order effects and merely tries to tackle the first-order effect
described above.

Nowadays, developers either hard code a likely number, such as ``64`` bytes, or
figure out exactly the right number by consulting their specific machine's
manual. The implementation is better positioned to do the exact same thing at
compile-time, we therefore propose to standardize existing practice, moving the
magic number from each developer's code base to each implementation.

A precise value can still be obtained from the operating system or using inline
assembly at runtime. This value can be passed to allocator implementations which
can guarantee alignment.

We further extend existing practice by offering two values:

* *False-sharing size*: a number that's suitable as offset between two objects
  to likely avoid false-sharing due to different runtime access patterns from
  different threads.
* *True-sharing size*: a number which should bound two objects' footprint and
  their initial alignment to likely promote true sharing between then.

In both cases these values are provided on a quality of implementation basis:
they're likely correct for the architectural information that the compiler was
given:

* When a virtual ISA is provided a wide discrepancy between the two numbers is
  to be expected.
* When a specific ISA is provided but no specific architecture implementation is
  then one might expect to be given known biggest L1 size and smallest L1 size
  amongst relevant/existing implementations of this ISA.
* When a specific architecture implementation is provided then one can expect
  both numbers to be the same, and be the same as that specific architecture's
  L1 cacheline size.

-----------------
Proposed addition
-----------------

We propose adding the following to the standard:

Under 30.3.1 Class ``thread`` [**thread.thread.class**]:

.. code-block:: c++

  namespace std {
    class thread {
      // ...
    public:
      static constexpr size_t hardware_false_sharing_size = /* implementation-defined */;
      static constexpr size_t hardware_true_sharing_size = /* implementation-defined */;
      // ...
    };
  }

Under 30.3.1.6 ``thread`` static members [**thread.thread.static**]:

``constexpr size_t hardware_false_sharing_size = /* implementation-defined */;``

This number is the minimum recommended offset between two concurrently-accessed
objects to avoid additional performance degradation due to contention introduced
by the implementation.

[*Example:*

.. code-block:: c++

  struct apart {
    alignas(hardware_false_sharing_size) atomic<int> flag1, flag2;
  };

— *end example*]

``constexpr size_t hardware_true_sharing_size = /* implementation-defined */;``

This number is the minimum recommended alignment and maximum recommended size of
contiguous memory occupied by two objects accessed with temporal locality by
concurrent threads.

[*Example:*

.. code-block:: c++

  alignas(hardware_true_sharing_size) struct colocated {
    atomic<int> flag;
    int tinydata;
  };
  static_assert(sizeof(colocated) <= hardware_true_sharing_size);

— *end example*]

The ``__cpp_lib_thread_hardware_sharing_size`` feature test macro should be
added.

.. _appendix:

--------
Appendix
--------

We informatively list a few ways in which the L1 cacheline size can be obtained
on different operating systems and architectures at runtime.

On OSX one would use:

.. code-block:: c++

  sysctlbyname("hw.cachelinesize", &cacheline_size, &sizeof_cacheline_size, 0, 0)

On Windows one would use:

.. code-block:: c++

  GetLogicalProcessorInformation(&buf[0], &sizeof_buf);
  for (i = 0; i != sizeof_buf / sizeof(SYSTEM_LOGICAL_PROCESSOR_INFORMATION); ++i) {
    if (buf[i].Relationship == RelationCache && buf[i].Cache.Level == 1)
      cacheline_size = buf[i].Cache.LineSize;

On Linux one would either use:

.. code-block:: c++

  p = fopen("/sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size", "r");
  fscanf(p, "%d", &cacheline_size);

or:

.. code-block:: c++

  sysconf(_SC_LEVEL1_DCACHE_LINESIZE);

On x86 one would use the ``CPUID`` Instruction with ``EAX = 80000005h``, which
leaves the result in ``ECX``, which needs further work to extract.

On ARM one would use ``mrs %[ctr], ctr_el0``, which needs further work to
extract.

===================================================================
D4523 ``constexpr std::thread::hardware_{true,false}_sharing_size``
===================================================================

:Author: JF Bastien
:Contact: jfb@google.com
:Author: Olivier Giroux
:Contact: ogiroux@nvidia.com
:Date: 2015-05-08
:URL: https://github.com/jfbastien/papers/blob/master/source/D4523.rst

.. TODO Update the URL above when this becomes an N paper.

---------
Rationale
---------

Each architecture implementation has a cacheline size which never
changes. Indeed, this number is deeply embedded in the caching hardware's
implementation, yet C++ doesn't expose this number as a ``constexpr``. This is
partly due to this cacheline size changing from one architecture implementation
to another within the same Instruction Set Architecture. Knowing which ISA the
compiler targets is therefore insufficient to get an exact cacheline size: one
has to target a specific architecture implementation.

The current methods to obtain the cacheline size are all runtime methods, not
``constexpr`` values, and are either ISA-dependent, OS-dependent, or use cache
timing. See the appendix_ for examples.

Having a ``constexpr`` value is useful, even when the ``constexpr`` is only a
likely good value instead of the exact one. This allows setting ``alignas`` on
datastructures. It isn't a guarantee, merely a good guess at what would
work. This is useful to separate members in a class which have different access
patterns based on the algorithm. A developer can reason about the caching
protocol, e.g. MOESI, and group members which the algorithms makes exclusive to
a thread of execution and separate them from elements which are shared between
threads of execution.

Typical examples where this matters are:

* Multiple-producer and multiple-consumer queue.
* The ``barrier`` example, as illustrated in N4522_.
* Grouping an atomic variable with the data it protects.
* Preventing false-sharing between objects with different runtime access
  patterns from different threads.
* Promoting true-sharing between objects which have the same runtime access
  patterns.

.. _N4522: http://wg21.link/N4522

The only significant cacheline size in these circumstances is L1 cacheline
size. Advanced high-performance applications will care about the effects of
cache associativity and ways, multiple cache hierarchy, page size, TLB size,
number of sockets, in-rack distance, intra-datacenter distance, inter-datacenter
distance, and much more. This paper explicity doesn't address second-order and
N\ :sup:`th`-order effects and merely tries to tackle the first-order effect
described above.

Nowadays, developers either hard code a likely number, such as ``64`` bytes, or
figure out exactly the right number by consulting their specific machine's
manual. See the appendix_ for examples. The implementation is better positioned
to do the exact same thing at compile-time, we therefore propose to standardize
existing practice, moving the magic number from each developer's code base to
each implementation.

A precise value can still be obtained from the operating system or using inline
assembly at runtime. This value can be passed to allocator implementations which
can guarantee alignment.

We further extend existing practice by offering two values:

* *False-sharing size*: a number that's suitable as offset between two objects
  to likely avoid false-sharing due to different runtime access patterns from
  different threads.
* *True-sharing size*: a number which should bound two objects' footprint and
  their initial alignment to likely promote true sharing between then.

In both cases these values are provided on a quality of implementation basis:
they're likely correct for the architectural information that the compiler was
given:

* When a virtual ISA is provided a wide discrepancy between the two numbers is
  to be expected.
* When a specific ISA is provided but no specific architecture implementation is
  then one might expect to be given known biggest L1 size and smallest L1 size
  amongst relevant/existing implementations of this ISA.
* When a specific architecture implementation is provided then one can expect
  both numbers to be the same, and be the same as that specific architecture's
  L1 cacheline size.

-----------------
Proposed addition
-----------------

We propose adding the following to the standard:

Under 30.3.1 Class ``thread`` [**thread.thread.class**]:

.. code-block:: c++

  namespace std {
    class thread {
      // ...
    public:
      static constexpr size_t hardware_false_sharing_size = /* implementation-defined */;
      static constexpr size_t hardware_true_sharing_size = /* implementation-defined */;
      // ...
    };
  }

Under 30.3.1.6 ``thread`` static members [**thread.thread.static**]:

``constexpr size_t hardware_false_sharing_size = /* implementation-defined */;``

This number is the minimum recommended offset between two concurrently-accessed
objects to avoid additional performance degradation due to contention introduced
by the implementation.

[*Example:*

.. code-block:: c++

  struct apart {
    alignas(hardware_false_sharing_size) atomic<int> flag1, flag2;
  };

— *end example*]

``constexpr size_t hardware_true_sharing_size = /* implementation-defined */;``

This number is the minimum recommended alignment and maximum recommended size of
contiguous memory occupied by two objects accessed with temporal locality by
concurrent threads.

[*Example:*

.. code-block:: c++

  alignas(hardware_true_sharing_size) struct colocated {
    atomic<int> flag;
    int tinydata;
  };
  static_assert(sizeof(colocated) <= hardware_true_sharing_size);

— *end example*]

The ``__cpp_lib_thread_hardware_sharing_size`` feature test macro should be
added.

.. _appendix:

--------
Appendix
--------

Compile-time cacheline size
===========================

We informatively list a few ways in which the L1 cacheline size is obtained in
different open-source projects at compile-time.

The Linux kernel defines the ``__cacheline_aligned`` macro which is configured
for each architecture through ``L1_CACHE_BYTES``. On some architectures this
value is determined through the configure-time option
``CONFIG_<ARCH>_L1_CACHE_SHIFT``, and on others the value of ``L1_CACHE_SHIFT``
is hard-coded in the architecture's ``include/asm/cache.h`` header.

Many open-source projects from Google contain a ``base/port.h`` header which
defines the ``CACHELINE_ALIGNED`` macro based on an explicit list of
architecture detection macros. These header files have often diverged. A token
example from the autofdo_ project is:

.. _autofdo: https://github.com/google/autofdo/blob/master/base/port.h

.. code-block:: c++

  // Cache line alignment
  #if defined(__i386__) || defined(__x86_64__)
  #define CACHELINE_SIZE 64
  #elif defined(__powerpc64__)
  // TODO(dougkwan) This is the L1 D-cache line size of our Power7 machines.
  // Need to check if this is appropriate for other PowerPC64 systems.
  #define CACHELINE_SIZE 128
  #elif defined(__arm__)
  // Cache line sizes for ARM: These values are not strictly correct since
  // cache line sizes depend on implementations, not architectures.  There
  // are even implementations with cache line sizes configurable at boot
  // time.
  #if defined(__ARM_ARCH_5T__)
  #define CACHELINE_SIZE 32
  #elif defined(__ARM_ARCH_7A__)
  #define CACHELINE_SIZE 64
  #endif
  #endif

  #ifndef CACHELINE_SIZE
  // A reasonable default guess.  Note that overestimates tend to waste more
  // space, while underestimates tend to waste more time.
  #define CACHELINE_SIZE 64
  #endif

  #define CACHELINE_ALIGNED __attribute__((aligned(CACHELINE_SIZE)))

Runtime cacheline size
======================

We informatively list a few ways in which the L1 cacheline size can be obtained
on different operating systems and architectures at runtime.

On OSX one would use:

.. code-block:: c++

  sysctlbyname("hw.cachelinesize", &cacheline_size, &sizeof_cacheline_size, 0, 0)

On Windows one would use:

.. code-block:: c++

  GetLogicalProcessorInformation(&buf[0], &sizeof_buf);
  for (i = 0; i != sizeof_buf / sizeof(SYSTEM_LOGICAL_PROCESSOR_INFORMATION); ++i) {
    if (buf[i].Relationship == RelationCache && buf[i].Cache.Level == 1)
      cacheline_size = buf[i].Cache.LineSize;

On Linux one would either use:

.. code-block:: c++

  p = fopen("/sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size", "r");
  fscanf(p, "%d", &cacheline_size);

or:

.. code-block:: c++

  sysconf(_SC_LEVEL1_DCACHE_LINESIZE);

On x86 one would use the ``CPUID`` Instruction with ``EAX = 80000005h``, which
leaves the result in ``ECX``, which needs further work to extract.

On ARM one would use ``mrs %[ctr], ctr_el0``, which needs further work to
extract.
